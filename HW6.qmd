---
title: "719HW6"
format: html
editor: visual
editor_options: 
  chunk_output_type: inline
---

## Question 1

### A

The saturated model has 6 parameters. 1 from the intercept, 1 from the treatment, 2 from the disease, and 2 from the interaction of disease and treatment.

### B

Model 1: $logit(p) = \beta_0 + \beta_1 * T$

Model 2: $logit(p) = \beta_0 + \beta_1 * D$

Model 3: $logit(p) = \beta_0 + (\beta_1*T) + (\beta_2 *D) + (\beta_3 * T*D)$

### C

Model 1 is suitable to answer question 1. Model 2 is suitable to answer question 2. Model 3 is suitable to answer question 3.

### D

#### Build df

```{r}
y <- c(51, 67, 42, 143, 97, 40)
n <- c(200, 158, 89, 315, 263, 75)
severity <- rep(c(0,1,2), 2)
treatment <- c(rep(0, 3), rep(1, 3))

df <- cbind.data.frame(y, n, severity, treatment)
df
```

#### Fit models

```{r}
mod_1 <- glm(cbind(y, n-y) ~ treatment, data = df, family = binomial(link = "logit"))
mod_2 <- glm(cbind(y, n-y) ~ severity, data = df, family = binomial(link = "logit"))
mod_3 <- glm(cbind(y, n-y) ~ treatment*severity, data = df, family = binomial(link = "logit"))
```

### E

DF of the null deviance: `r mod_1$df.null`

DF of the residual deviance for Model 1: `r mod_1$df.residual`

DF of the residual deviance for Model 2: `r mod_2$df.residual`

DF of the residual deviance for Model 3: `r mod_3$df.residual`

### F

```{r}
mod1_sum <- summary(mod_1)
```

The p-value for the model's treatment coefficient is `r mod1_sum$coefficients[2,4]`, which is statistically significant. This means the coefficient is significantly different from 0 and we can use the estimator to estimate the estimand. 

The odds of hospitalization increases by a factor of `r round(exp(mod1_sum$coefficients[2,1]), 3)`, or 35%, when an individual is administered Drug B compared to Drug A. Drug A is better for preventing hospitalization.

### G

```{r}
mod2_sum <- summary(mod_2)
```

The p-value for the model's severity coefficient is `r mod2_sum$coefficients[2,4]`, which is statistically significant. This means the coefficient is significantly different from 0 and we can use it to estimate our parameter. It also means that severity is statistically significantly associated with hospitalization.

A 1 unit increase in severity results in a `r round(exp(mod2_sum$coefficients[2,1]), 3)` odds increase of hospitalization when comparing Drug A to Drug B, which is 23.1% increase.

### H

```{r}
mod3_sum <- summary(mod_3)
```


$$
= \frac{exp(\hat{\beta_0} + \hat{\beta_2})} {exp(\hat{\beta_0} + \hat{\beta_1} + \hat{2\beta_2} + \hat{2\beta_3})} = exp(-\hat{\beta_1} - \hat{\beta_2} -\hat{2\beta_3}) = exp(-0.7032 -.511 - 2*(-.5122) ) = exp(-.1898) = 0.827 
$$


95% CI: 

```{r}
L <- cbind(c(0,-1, -1, -2))
Lb <- t(L)%*%mod_3$coef
varLb <- t(L)%*%mod3_sum$cov.unscaled%*%L
CILb <- Lb + c(-1, 1)*qnorm(1-.05/2)*sqrt(varLb)
exp(CILb)
```



### I

I can use model 3 to answer question 3. The interaction term is significant, which means the treatment effect changes for different levels of severity, and vice versa.

To show this, I will compare the effect of a change in severity in two different situations, one where treatment == 0 and one where treatment == 1.

```{r}
mod3_b <- mod3_sum$coefficients
```


$$
\frac{exp(\beta_0 + \beta1*0 + \beta_2*1 + \beta_3*0*1) } {exp(\beta_0 + \beta1*0 + \beta_2*2 + \beta_3*0*2)} = \frac{0.6205}{1.0343} = 0.5999
$$

$$
\frac{exp(\beta_0 + \beta1*1 + \beta_2*1 + \beta_3*1*1) } {exp(\beta_0 + \beta1*1 + \beta_2*2 + \beta_3*1*2)} = \frac{0.7503}{0.7494} = 1.0012
$$
This shows that the odds ratio between levels of severity changes differently for different levels of disease. This shows that disease severity is an effect modifier.

### J

NO
YES
YES

Only model 1 vs Model 3 & Model 2 vs Model 3 can be compared using the LRT.

```{r}
anova(mod_1, mod_3, test = "LRT")
```

```{r}
anova(mod_2, mod_3, test = "LRT")
```

The larger model is preferred in both cases since $H_0 = \text{Smaller model is preferred}$, $H_a: \text{Larger model is preferred}$ and $p < 0.05$, so the interaction term should be included.


## Question 2

### A

```{r}
y <- c(55, 52, 57, 55, 50, 50)
n <- c(102, 99, 108, 76, 81, 90)
force <- rep(c(40, 150, 350), 2)
newstor <- c(rep("Control", 3), rep("Treatment", 3))

df2 <- cbind.data.frame(y, n, force, newstor)
```

```{r}
fit2.1 <- glm(cbind(y, n-y) ~ newstor, family = binomial(link = "logit"), data = df2)
fit2.1
```

```{r}
fit2.2 <- glm(cbind(y, n-y) ~ newstor*log(force), family = binomial(link = "logit"), data = df2)
fit2.2
```

### B

```{r}
df2_ungrouped_left <- as.data.frame(rbind(
cbind(force=rep(df2[,"force"], df2[,"y"]), n=1, y=1),
cbind(force=rep(df2[,"force"], df2[,"n"]-df2[,"y"]), n=1, y=0)
))

df2_ungrouped_right <- as.data.frame(rbind(
cbind(newstor=rep(df2[,"newstor"], df2[,"y"])),
cbind(newstor=rep(df2[,"newstor"], df2[,"n"]-df2[,"y"]))
))

df2_ungrouped <- cbind(df2_ungrouped_left, df2_ungrouped_right)

df2_ungrouped$y <- as.numeric(df2_ungrouped$y)
df2_ungrouped$newstor <- as.factor(df2_ungrouped$newstor)
```

```{r}
fit2.1.2 <- glm(y ~ newstor, family = binomial(link = "logit"), data = df2_ungrouped)
fit2.1.2
```

```{r}
fit2.2.2 <- glm(y ~ newstor * log(force), family = binomial(link = "logit"), data = df2_ungrouped)
fit2.2.2
```

The models give the same conclusions using grouped and ungrouped data, though some calculated values are different such as the deviances.

### C

```{r}
an_1 <- anova(fit2.1, fit2.2, test = "LRT")
an_1
pval_1 <- an_1$`Pr(>Chi)`[2]
```

```{r}
an_2 <- anova(fit2.1.2, fit2.2.2, test = "LRT")
an_2
pval_2 <- an_2$`Pr(>Chi)`[2]
```
They do give the same result.

### D

$$
H_0: \text{Model 1 better than Model 2}
$$

$$
H_a: \text{Model 2 better than Model 1}
$$

The p-value is not significant for either test (`r round(pval_1, 4)` & `r round(pval_2,4)`), meaning we fail to reject the null and conclude that the simpler model is better, i.e. we do not need to include log(force) at all in the model. It is better to use just the storage condition to predict the outcome than a model that includes storage and log(force).



